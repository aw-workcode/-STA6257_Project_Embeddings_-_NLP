---
title: "Using Vector Embeddings For Sentiment Analysis"
author: "Rod Acosta, Kevin Furbish, Ibrahim Khan, Anthony Washington"
format:
  revealjs:
    theme: moon
    incremental: true 
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---
# Methods

## What is a neural Network?
- A neural network is a type of algorithm that mimics the structure and function 
of the human brain. Their goal is to create an artificial system that can process
and analyze data in a similar way.
- There are different types of neural networks but there are some common elements
between most of them. Those elements are:
  - Artificial Neurons
  - Layers

## Neural Network Layers {.smaller}
- Neural networks usually have three types of layers:
  - Input Layer
  - Hidden layers
  - Output layer
  
![](nnLayers.png){fig-align="center"}

## What are embeddings? {.smaller}
- Embeddings are a technique that allow us to map words or phrases into a corresponding
vector of real numbers, where the position and direction of the vector capture the word's
semantic meaning in relation to other words. 
- They make high-dimensional data like words readable
to our algorithm/model and allows our model to recognize and learn meaningful relationships 
and similarities between words

:::: {.columns}
::: {.column width="40%"}
![](embLayer.png){fig-align="center"}
:::
::: {.column width="60%"}
![](How-Embeddings-Work.jpg){fig-align="center"}
:::
::::

## Dense Layer & Cosine Similarity {.smaller}
:::: {.columns}
::: {.column width="50%"}
- Cosine Similarity
  - Measures the cosine of the angle between two non-zero vectors, providing a measure of similarity.
  - The smaller the angle the higher the similarity between the two vectors.
  - $cosine\_similarity(u,v) = \frac{u.v}{||u|| ||v||}$
![](cosine.jpg){fig-align="center"}
:::
::: {.column width="50%"}
- Dense Layer
  - A logistic regression model with a sigmoid activation function used for binary classification. 
  - It outputs the probability that the input belongs to a positive class.
  - $y=\sigma(Wâ‹…z+b)$
  - Where:
     - z is the flattened input vector.
     - W is the weight vector.
     - b is the bias term.
     - $\sigma(x) = \frac{1}{1+e^{-x}}$ is the sigmoid function.
:::
::::

## Sentiment Analysis
- Through the use of a neural network and it's hidden layers (embedding & dense), and the cosine similarity we are able to take inputs
and classify them as being part of a positive or negative class based on what our model has learned from our training dataset.